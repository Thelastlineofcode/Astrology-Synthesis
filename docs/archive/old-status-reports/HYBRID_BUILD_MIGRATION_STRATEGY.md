# DATA MIGRATION & INTEGRATION STRATEGY

## From Isolated MVPs â†’ Unified Platform

**Duration**: 2 weeks (Dec 3-17, 2025)  
**Timeline**: Weeks 3-4 of hybrid execution  
**Team**: Backend Lead + DevOps + (1 Frontend for testing)  
**Objective**: Seamlessly merge Dasha Timer + Compatibility into single platform without data loss or downtime

---

## OVERVIEW

### Current State (End of Week 2)

```
Dasha Timer MVP:
â”œâ”€â”€ 500+ active users
â”œâ”€â”€ 1000+ signups total
â”œâ”€â”€ PostgreSQL database (schema_dasha)
â”œâ”€â”€ Backend API running on Railway
â”œâ”€â”€ Frontend on Vercel
â””â”€â”€ Revenue: $100-200 MRR

Compatibility MVP:
â”œâ”€â”€ 2000+ active users
â”œâ”€â”€ 3000+ signups total
â”œâ”€â”€ PostgreSQL database (schema_compat)
â”œâ”€â”€ Backend API running on Railway
â”œâ”€â”€ Frontend on Vercel
â””â”€â”€ Revenue: $300-500 MRR

Total: 4000+ signups, $400-700 MRR, 2 separate systems
```

### Target State (End of Week 4)

```
Unified Mula Platform:
â”œâ”€â”€ 4000+ users (migrated from both apps)
â”œâ”€â”€ 1 database (unified schema)
â”œâ”€â”€ 1 backend (extended FastAPI)
â”œâ”€â”€ 1 frontend (both features visible)
â”œâ”€â”€ 1 auth system (federated logins)
â”œâ”€â”€ 1 payment system (Stripe unified)
â”œâ”€â”€ 1 notification system (FCM unified)
â””â”€â”€ Revenue: $400-700 MRR (maintained, not increased yet)

Plus: Ready for features #3-5 in Week 5+
```

---

## PHASE 1: PREPARATION (Days 1-3)

### Day 1: Assessment & Planning

**Tasks:**

```
Backend Lead:
â”œâ”€â”€ Analyze current schema_dasha (PostgreSQL)
â”œâ”€â”€ Analyze current schema_compat (PostgreSQL)
â”œâ”€â”€ Identify data conflicts/duplicates
â”œâ”€â”€ Create unified schema design
â”œâ”€â”€ Document all differences
â””â”€â”€ Plan rollback strategy

DevOps:
â”œâ”€â”€ Backup all data (both databases)
â”œâ”€â”€ Create snapshot of both systems
â”œâ”€â”€ Setup staging environment
â”œâ”€â”€ Create migration test database
â””â”€â”€ Setup rollback automation

Frontend Lead:
â”œâ”€â”€ Audit current frontend for Dasha Timer
â”œâ”€â”€ Audit current frontend for Compatibility
â”œâ”€â”€ Identify shared components
â”œâ”€â”€ Plan unified navigation
â””â”€â”€ Create feature flags for gradual rollout
```

### Unified Database Schema

```sql
-- New unified schema

-- Users (merged, deduplicated)
CREATE TABLE users (
    id UUID PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    username VARCHAR(100),
    oauth_provider VARCHAR(50),
    oauth_id VARCHAR(255),
    created_at TIMESTAMP DEFAULT NOW(),
    last_login TIMESTAMP,
    INDEX (email),
    INDEX (oauth_provider, oauth_id)
);

-- Birth Charts (merged)
CREATE TABLE birth_charts (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    birth_date TIMESTAMP NOT NULL,
    birth_time VARCHAR(8),
    birth_location_lat FLOAT,
    birth_location_lng FLOAT,
    birth_location_name VARCHAR(255),
    timezone_offset INT,
    chart_data JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    is_default BOOLEAN DEFAULT false,
    INDEX (user_id, created_at),
    INDEX (user_id, is_default)
);

-- Dasha Data (from Dasha Timer)
CREATE TABLE dasha_data (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id),
    chart_id UUID NOT NULL REFERENCES birth_charts(id),
    current_dasha VARCHAR(50),
    current_dasha_start DATE,
    current_dasha_end DATE,
    dasha_sequence JSONB,
    calculated_at TIMESTAMP DEFAULT NOW(),
    INDEX (user_id, updated_at)
);

-- Compatibility Results (from Compatibility Checker)
CREATE TABLE compatibility_results (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id),
    chart1_id UUID NOT NULL REFERENCES birth_charts(id),
    chart2_id UUID REFERENCES birth_charts(id),
    overall_score INT,
    venus_score INT,
    mars_score INT,
    moon_score INT,
    sun_score INT,
    detailed_breakdown JSONB,
    share_code VARCHAR(20) UNIQUE,
    calculated_at TIMESTAMP DEFAULT NOW(),
    view_count INT DEFAULT 0,
    INDEX (user_id, calculated_at),
    INDEX (share_code)
);

-- Subscriptions (unified)
CREATE TABLE subscriptions (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id),
    stripe_subscription_id VARCHAR(255) UNIQUE,
    plan_name VARCHAR(50),  -- 'free', 'basic', 'premium'
    status VARCHAR(50),
    started_at TIMESTAMP DEFAULT NOW(),
    next_billing_at TIMESTAMP,
    INDEX (user_id, status)
);

-- FCM Tokens (unified)
CREATE TABLE fcm_tokens (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id),
    token VARCHAR(500) NOT NULL,
    device_name VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT true,
    UNIQUE (user_id, token)
);

-- User Preferences (unified)
CREATE TABLE user_preferences (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id) UNIQUE,
    notifications_enabled BOOLEAN DEFAULT true,
    daily_dasha_reminder BOOLEAN DEFAULT true,
    email_enabled BOOLEAN DEFAULT true,
    marketing_emails BOOLEAN DEFAULT false,
    daily_reminder_time TIME DEFAULT '09:00',
    timezone VARCHAR(50) DEFAULT 'UTC',
    data JSONB DEFAULT '{}',
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Activity Log (new for analytics)
CREATE TABLE activity_log (
    id UUID PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES users(id),
    action VARCHAR(100),  -- 'viewed_dasha', 'calculated_compat', etc
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    INDEX (user_id, created_at),
    INDEX (created_at)
);
```

### Day 2: Migration Scripts

**Create Python migration scripts:**

```python
# migration/migrate_users.py

import psycopg2
from uuid import uuid4
from datetime import datetime

def migrate_users():
    """
    Migrate users from both old schemas to new unified schema.
    Deduplicate by email.
    """

    dasha_conn = psycopg2.connect(os.getenv('DASHA_DATABASE_URL'))
    compat_conn = psycopg2.connect(os.getenv('COMPAT_DATABASE_URL'))
    unified_conn = psycopg2.connect(os.getenv('UNIFIED_DATABASE_URL'))

    dasha_cursor = dasha_conn.cursor()
    compat_cursor = compat_conn.cursor()
    unified_cursor = unified_conn.cursor()

    try:
        # Get all users from Dasha app
        dasha_cursor.execute("SELECT id, email, username, created_at FROM users")
        dasha_users = dasha_cursor.fetchall()

        # Get all users from Compat app
        compat_cursor.execute("SELECT id, email, username, created_at FROM users")
        compat_users = compat_cursor.fetchall()

        # Track mappings for later (old_id -> new_id)
        migrations = {
            'dasha': {},
            'compat': {}
        }

        # Merge users, deduplicating by email
        seen_emails = set()
        all_users = []

        for user in dasha_users:
            if user['email'] not in seen_emails:
                all_users.append(('dasha', user))
                seen_emails.add(user['email'])

        for user in compat_users:
            if user['email'] not in seen_emails:
                all_users.append(('compat', user))
                seen_emails.add(user['email'])

        # Insert into unified database
        for source, user in all_users:
            new_id = str(uuid4())

            unified_cursor.execute("""
                INSERT INTO users (id, email, username, created_at)
                VALUES (%s, %s, %s, %s)
            """, (new_id, user['email'], user['username'], user['created_at']))

            migrations[source][user['id']] = new_id

        unified_conn.commit()

        print(f"âœ… Migrated {len(all_users)} users")
        return migrations

    except Exception as e:
        print(f"âŒ Error migrating users: {e}")
        unified_conn.rollback()
        raise
    finally:
        dasha_cursor.close()
        compat_cursor.close()
        unified_cursor.close()
        dasha_conn.close()
        compat_conn.close()
        unified_conn.close()
```

```python
# migration/migrate_birth_charts.py

def migrate_birth_charts(user_mappings):
    """Migrate birth charts from both apps."""

    dasha_conn = psycopg2.connect(os.getenv('DASHA_DATABASE_URL'))
    compat_conn = psycopg2.connect(os.getenv('COMPAT_DATABASE_URL'))
    unified_conn = psycopg2.connect(os.getenv('UNIFIED_DATABASE_URL'))

    dasha_cursor = dasha_conn.cursor()
    compat_cursor = compat_conn.cursor()
    unified_cursor = unified_conn.cursor()

    try:
        chart_mappings = {'dasha': {}, 'compat': {}}

        # Migrate Dasha app charts
        dasha_cursor.execute("SELECT * FROM birth_charts")
        dasha_charts = dasha_cursor.fetchall()

        for chart in dasha_charts:
            new_id = str(uuid4())
            new_user_id = user_mappings['dasha'].get(chart['user_id'])

            if not new_user_id:
                print(f"âš ï¸  User {chart['user_id']} not found, skipping chart")
                continue

            unified_cursor.execute("""
                INSERT INTO birth_charts
                (id, user_id, birth_date, birth_time, birth_location_lat,
                 birth_location_lng, birth_location_name, timezone_offset,
                 chart_data, created_at, is_default)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (new_id, new_user_id, chart['birth_date'], chart['birth_time'],
                  chart['birth_location_lat'], chart['birth_location_lng'],
                  chart['birth_location_name'], chart['timezone_offset'],
                  json.dumps(chart['chart_data']), chart['created_at'],
                  chart['is_default']))

            chart_mappings['dasha'][chart['id']] = new_id

        # Migrate Compat app charts (same process)
        compat_cursor.execute("SELECT * FROM birth_charts")
        compat_charts = compat_cursor.fetchall()

        for chart in compat_charts:
            # Same logic as above but for compat
            pass

        unified_conn.commit()
        print(f"âœ… Migrated {len(dasha_charts) + len(compat_charts)} birth charts")
        return chart_mappings

    except Exception as e:
        print(f"âŒ Error migrating charts: {e}")
        unified_conn.rollback()
        raise
```

### Day 3: Test Migration & Validation

```python
# migration/validate_migration.py

def validate_migration():
    """Verify migration integrity."""

    unified_conn = psycopg2.connect(os.getenv('UNIFIED_DATABASE_URL'))
    cursor = unified_conn.cursor()

    checks = {
        'users': 0,
        'birth_charts': 0,
        'dasha_data': 0,
        'compatibility_results': 0,
        'errors': []
    }

    # Check users
    cursor.execute("SELECT COUNT(*) FROM users")
    checks['users'] = cursor.fetchone()[0]
    print(f"âœ… {checks['users']} users migrated")

    # Check for NULL user_ids (orphaned records)
    cursor.execute("""
        SELECT COUNT(*) FROM birth_charts WHERE user_id IS NULL
    """)
    orphaned = cursor.fetchone()[0]
    if orphaned > 0:
        checks['errors'].append(f"âš ï¸  {orphaned} orphaned birth_charts")

    # Check for duplicate emails
    cursor.execute("""
        SELECT email, COUNT(*) as count
        FROM users
        GROUP BY email
        HAVING COUNT(*) > 1
    """)
    duplicates = cursor.fetchall()
    if duplicates:
        checks['errors'].append(f"âš ï¸  {len(duplicates)} duplicate emails found")

    # Verify data integrity
    cursor.execute("""
        SELECT COUNT(*) FROM birth_charts WHERE chart_data IS NULL
    """)
    null_charts = cursor.fetchone()[0]
    if null_charts > 0:
        checks['errors'].append(f"âš ï¸  {null_charts} charts with NULL data")

    return checks

# Run migration
print("Starting migration...")
user_maps = migrate_users()
chart_maps = migrate_birth_charts(user_maps)
dasha_maps = migrate_dasha_data(user_maps, chart_maps)
compat_maps = migrate_compatibility_results(user_maps, chart_maps)

# Validate
validation = validate_migration()
print(f"Migration validation: {validation}")
```

---

## PHASE 2: CUTOVER (Days 4-7)

### Day 4: Staging Test

**Test in staging environment first:**

```
1. Deploy unified database to staging
2. Deploy migrated data
3. Deploy new unified backend (FastAPI)
4. Deploy new unified frontend
5. QA tests:
   â”œâ”€â”€ Login with old credentials (federated)
   â”œâ”€â”€ View Dasha Timer data
   â”œâ”€â”€ View Compatibility results
   â”œâ”€â”€ Calculate new compatibility
   â”œâ”€â”€ Update preferences
   â”œâ”€â”€ Make purchase (Stripe)
   â””â”€â”€ Send notifications (FCM)
6. Load testing: 500 concurrent users
7â”€â”€ Rollback test (verify backups work)
```

### Day 5: Pre-Launch Prep

**Prepare users for transition:**

```
1. Send email: "We're launching an improved Mula platform!"
2. Inform users:
   â”œâ”€â”€ All data will be preserved
   â”œâ”€â”€ New features coming soon
   â”œâ”€â”€ No action needed from them
   â”œâ”€â”€ Scheduled maintenance (1 hour downtime)
   â””â”€â”€ New login might be required (but old credentials still work)

3. Create FAQ:
   â”œâ”€â”€ "Will I lose my data?" â†’ No, all migrated
   â”œâ”€â”€ "Do I need new account?" â†’ No, federated login
   â”œâ”€â”€ "Why the downtime?" â†’ Consolidating systems
   â”œâ”€â”€ "When can I use new features?" â†’ Coming in Week 5
   â””â”€â”€ "Support email" â†’ Support link

4. Prepare support team:
   â”œâ”€â”€ Brief on what's changing
   â”œâ”€â”€ Common issues + solutions
   â”œâ”€â”€ Escalation procedures
   â””â”€â”€ Go/no-go meeting
```

### Day 6: Production Cutover

**Execute migration to production (minimal downtime):**

```
Timeline (assume 4 AM UTC = least active time):

3:45 AM: Send notifications
â”œâ”€â”€ "Maintenance starting in 15 minutes"
â”œâ”€â”€ Push notification + Email
â””â”€â”€ Display banner on app

4:00 AM: Take both services offline
â”œâ”€â”€ Dasha Timer â†’ Maintenance page
â”œâ”€â”€ Compatibility Checker â†’ Maintenance page
â”œâ”€â”€ Set DNS to static maintenance pages
â””â”€â”€ Verify traffic redirects

4:05 AM: Stop all active processes
â”œâ”€â”€ Shutdown Dasha Timer backend
â”œâ”€â”€ Shutdown Compatibility backend
â”œâ”€â”€ Drain in-flight requests
â””â”€â”€ Wait for cleanup

4:10 AM: Run migration scripts
â”œâ”€â”€ Execute migrate_users.py (3-5 min)
â”œâ”€â”€ Execute migrate_birth_charts.py (5-10 min)
â”œâ”€â”€ Execute migrate_dasha_data.py (2-3 min)
â”œâ”€â”€ Execute migrate_compatibility_results.py (2-3 min)
â”œâ”€â”€ Validate migration (3-5 min)
â””â”€â”€ Total: ~20 minutes

4:35 AM: Deploy unified platform
â”œâ”€â”€ Deploy backend to Railway (new container)
â”œâ”€â”€ Deploy frontend to Vercel (new deployment)
â”œâ”€â”€ Run database migrations
â”œâ”€â”€ Verify health checks
â””â”€â”€ Confirm services up

4:50 AM: Test in production
â”œâ”€â”€ Test login (federated)
â”œâ”€â”€ Verify user data visible
â”œâ”€â”€ Check Dasha calculations
â”œâ”€â”€ Verify Compatibility results
â”œâ”€â”€ Test Stripe integration
â””â”€â”€ Test FCM notifications

5:00 AM: Go live
â”œâ”€â”€ Remove maintenance pages
â”œâ”€â”€ Update DNS to production
â”œâ”€â”€ Send "We're back!" notification
â”œâ”€â”€ Monitor error tracking (Sentry)
â””â”€â”€ Monitor performance (Plausible)

Expected downtime: 45-60 minutes
```

### Day 7: Post-Launch Monitoring

```
Continuous monitoring:
â”œâ”€â”€ Sentry: Check for errors (target: <1% error rate)
â”œâ”€â”€ Plausible: Monitor traffic patterns
â”œâ”€â”€ Database: Monitor performance, query times
â”œâ”€â”€ API response times: Target <500ms p95
â”œâ”€â”€ Notifications: Verify FCM delivery
â””â”€â”€ Payments: Verify Stripe working

User support:
â”œâ”€â”€ Monitor support email for issues
â”œâ”€â”€ Have rollback procedure ready
â”œâ”€â”€ Document any issues + fixes
â””â”€â”€ Daily standup sync
```

---

## PHASE 3: FEDERATION & UNIFICATION (Days 8-14)

### Day 8-9: Federated Auth Implementation

**Users can now login with credentials from either old system:**

```python
# backend/services/federated_auth.py

class FederatedAuthService:
    """
    Allow users to login with:
    1. Email/password (new unified system)
    2. Old Dasha Timer OAuth token
    3. Old Compatibility OAuth token
    """

    def login_legacy_token(self, legacy_token: str) -> dict:
        """
        User provides old JWT token from either service.
        Validate it, verify source, create new unified token.
        """

        # Decode legacy token (from either service)
        try:
            # Try Dasha Timer key
            payload = jwt.decode(
                legacy_token,
                DASHA_JWT_SECRET,
                algorithms=['HS256']
            )
            legacy_source = 'dasha'
        except:
            try:
                # Try Compatibility key
                payload = jwt.decode(
                    legacy_token,
                    COMPAT_JWT_SECRET,
                    algorithms=['HS256']
                )
                legacy_source = 'compat'
            except:
                raise ValueError("Invalid token")

        # Get email from payload
        email = payload.get('email')
        old_user_id = payload.get('user_id')

        # Look up user in unified database
        user = User.query.filter_by(email=email).first()
        if not user:
            raise ValueError(f"User {email} not found in unified system")

        # Create new unified JWT token
        new_token = jwt.encode({
            'user_id': str(user.id),
            'email': user.email,
            'legacy_source': legacy_source,
            'legacy_user_id': old_user_id,
            'exp': datetime.utcnow() + timedelta(days=30)
        }, UNIFIED_JWT_SECRET, algorithm='HS256')

        # Log migration for analytics
        ActivityLog.create(
            user_id=user.id,
            action='legacy_login_migrated',
            metadata={'source': legacy_source}
        )

        return {
            'token': new_token,
            'user_id': str(user.id),
            'email': user.email,
            'message': 'Welcome to unified Mula platform!'
        }
```

### Day 10-11: Unified Dashboard

**Create single dashboard showing both features:**

```typescript
// frontend/app/dashboard/page.tsx

export default function DashboardPage() {
  const { user } = useAuth();
  const { data: dasha } = useDashaData();
  const { data: lastCompatibility } = useLastCompatibility();

  return (
    <div className="dashboard">
      {/* Header */}
      <header>
        <h1>Welcome, {user.name || user.email}</h1>
        <p>Your Personal Astrology Hub</p>
      </header>

      {/* Feature Cards */}
      <div className="feature-grid">
        {/* Dasha Timer Card */}
        <FeatureCard
          title="Daily Dasha Timer"
          icon="â°"
          current={dasha?.current_dasha}
          daysRemaining={dasha?.days_remaining}
          onClick={() => router.push('/dasha')}
        />

        {/* Compatibility Card */}
        <FeatureCard
          title="Cosmic Compatibility"
          icon="ğŸ’•"
          subtitle={lastCompatibility ? `${lastCompatibility.overall_score}% with ${lastCompatibility.partner_name}` : "Check yours"}
          onClick={() => router.push('/compatibility')}
        />

        {/* Coming Soon Cards */}
        <ComingSoonCard title="Moon Phase Rituals" icon="ğŸŒ™" />
        <ComingSoonCard title="Remedy of the Day" icon="ğŸ”®" />
        <ComingSoonCard title="AI Oracle Chat" icon="âœ¨" />
      </div>

      {/* Subscription Status */}
      <SubscriptionBanner />

      {/* Recent Activity */}
      <RecentActivity />
    </div>
  );
}
```

### Day 12-13: Unified Settings & Preferences

```typescript
// frontend/app/dashboard/settings/page.tsx

export default function SettingsPage() {
  return (
    <div className="settings">
      <h2>Settings</h2>

      <SettingsSection title="Notifications">
        <NotificationPreferences />
        {/* Options for all features */}
      </SettingsSection>

      <SettingsSection title="Birth Charts">
        <BirthChartManager />
        {/* Manage all charts from both services */}
      </SettingsSection>

      <SettingsSection title="Subscription">
        <SubscriptionManager />
      </SettingsSection>

      <SettingsSection title="Account">
        <AccountSettings />
        <DeleteAccount />
      </SettingsSection>
    </div>
  );
}
```

### Day 14: Completion & Handoff

```
Final checks:
â”œâ”€â”€ âœ… All user data migrated
â”œâ”€â”€ âœ… All logins working
â”œâ”€â”€ âœ… Dashboard unified
â”œâ”€â”€ âœ… Settings consolidated
â”œâ”€â”€ âœ… Notifications still working
â”œâ”€â”€ âœ… Payments still working
â”œâ”€â”€ âœ… Analytics tracking
â”œâ”€â”€ âœ… Documentation updated
â””â”€â”€ âœ… Team trained on new system

Metrics:
â”œâ”€â”€ 4000+ users unified
â”œâ”€â”€ 1500+ birth charts migrated
â”œâ”€â”€ 1000+ compatibility results preserved
â”œâ”€â”€ $400-700 MRR maintained
â”œâ”€â”€ <1% data loss
â”œâ”€â”€ <2% failed logins
â””â”€â”€ 100% uptime (post-migration)

Ready for Week 5: Build 3 new features (Rituals, Remedy, Oracle)
```

---

## ROLLBACK PROCEDURES

### If Something Goes Wrong

```
Level 1: Minor bugs (users can't login to one service)
â”œâ”€â”€ Fix and redeploy
â”œâ”€â”€ Notify affected users
â””â”€â”€ Continue

Level 2: Data integrity issues (some users' data corrupted)
â”œâ”€â”€ Identify affected users
â”œâ”€â”€ Restore from backup
â”œâ”€â”€ Redeploy with fix
â”œâ”€â”€ Notify affected users
â””â”€â”€ Full audit + retry

Level 3: Critical failure (services down, data loss)
â”œâ”€â”€ ACTIVATE ROLLBACK PROCEDURE:
â”‚   â”œâ”€â”€ Restore both old databases from backups
â”‚   â”œâ”€â”€ Redeploy old Dasha Timer service
â”‚   â”œâ”€â”€ Redeploy old Compatibility service
â”‚   â”œâ”€â”€ Update DNS to point to old services
â”‚   â””â”€â”€ Notify all users
â”œâ”€â”€ Post-mortem analysis
â”œâ”€â”€ Fix issues in staging
â””â”€â”€ Retry migration in 1 week

Estimated rollback time: 30-45 minutes to old state
```

---

## COMMUNICATION PLAN

### To Users

**Before Migration:**

```
Subject: "Mula Platform Upgrade - This Saturday at 4 AM UTC"

Hi [User],

We're consolidating Dasha Timer and Compatibility Checker into one unified Mula platform!

ğŸ“… What's happening:
- Short maintenance (45-60 minutes)
- All your data is preserved
- New features coming soon
- No action needed from you

âœ… What you can expect:
- Faster performance
- Better notifications
- Unified preferences
- New features launching next week

â° Scheduled maintenance:
- Saturday, Dec 6, 4:00-5:00 AM UTC
- You'll see maintenance page
- Services back online after ~1 hour

Questions? Support@mula.app
```

**After Migration:**

```
Subject: "âœ¨ Welcome to Unified Mula Platform"

Hi [User],

You're now on our new unified platform!

ğŸ‰ What's new:
- Single dashboard for all features
- Faster calculations
- Better notifications
- Seamless experience

ğŸš€ Coming next week:
- Moon Phase Rituals
- Remedy of the Day
- AI Oracle Chat
- And more...

Enjoy exploring!
```

### To Team

**Pre-migration sync:**

- Engineering lead: reviews migration scripts
- QA: reviews test plan
- Support: briefs on issues + solutions
- Operations: confirms infrastructure ready

**Go/no-go meeting:**

- All leads present
- Review: staging test results
- Confirm: all systems ready
- Decision: proceed or delay?

---

## RISK MITIGATION

| Risk                    | Probability | Impact                  | Mitigation                                   |
| ----------------------- | ----------- | ----------------------- | -------------------------------------------- |
| Migration takes >1 hour | Medium      | User frustration        | Test staging thoroughly, have rollback ready |
| Users can't login       | High        | Service dead            | Federated auth tested beforehand             |
| Data corruption         | Low         | Data loss, legal issues | Backups, validation scripts, audit trail     |
| Performance degrades    | Medium      | Users leave             | Load test, optimize queries                  |
| Stripe breaks           | Low         | No revenue              | Test Stripe webhook before cutover           |

---

## SUCCESS CRITERIA

```
âœ… Migration Complete When:
â”œâ”€â”€ 4000+ users migrated
â”œâ”€â”€ All data validated (100% integrity)
â”œâ”€â”€ Federated login working
â”œâ”€â”€ Dashboard unified
â”œâ”€â”€ 0 critical bugs
â”œâ”€â”€ <2% failed logins
â”œâ”€â”€ Performance: p95 <500ms
â”œâ”€â”€ 0 unplanned downtime
â”œâ”€â”€ $400-700 MRR maintained
â””â”€â”€ All users can see both features

Ready for Week 5:
â”œâ”€â”€ Full platform architecture in place
â”œâ”€â”€ 3 new features can be added easily
â”œâ”€â”€ 10,000+ user capacity proven
â””â”€â”€ $1M+ ARR roadmap enabled
```

---

## TIMELINE SUMMARY

```
Week 1 (Nov 8-15): Dasha Timer MVP launched
Week 2 (Nov 15-22): Compatibility Checker launched
Week 3 (Nov 22-29): Data Migration
â”œâ”€â”€ Days 1-3: Preparation
â”œâ”€â”€ Days 4-5: Testing
â”œâ”€â”€ Days 6-7: Cutover
â””â”€â”€ Days 8-14: Federation

Week 4 (Nov 29-Dec 6): Unified Dashboard
â”œâ”€â”€ Days 1-3: Federated auth
â”œâ”€â”€ Days 4-7: Dashboard + Settings
â””â”€â”€ Days 8-10: Quality assurance

Week 5+ (Dec 9+): Build 3 New Features
â”œâ”€â”€ Moon Phase Rituals
â”œâ”€â”€ Remedy of the Day
â”œâ”€â”€ AI Oracle Chat

Total: 4-week journey from "build first MVP" to "5-feature unified platform"
```

**Ready to execute?** ğŸš€
